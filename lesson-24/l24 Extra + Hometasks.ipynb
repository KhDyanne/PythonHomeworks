{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Info about Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must read"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with a custom aggregation function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas provides a number of aggregation functions to use with the groupby object. At some\n",
    "point, you may need to write your own custom user-defined function that does not exist in\n",
    "pandas or NumPy.\n",
    "\n",
    "In this recipe, we use the college dataset to calculate the mean and standard deviation\n",
    "of the undergraduate student population per state. We then use this information to find the\n",
    "maximum number of standard deviations from the mean that any single population value\n",
    "is per state."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the college dataset, and find the mean and standard deviation of the\n",
    "undergraduate population by state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>2493.0</td>\n",
       "      <td>4052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>2790.0</td>\n",
       "      <td>4658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1644.0</td>\n",
       "      <td>3143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>4130.0</td>\n",
       "      <td>14894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>1513.0</td>\n",
       "      <td>2194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA</th>\n",
       "      <td>2271.0</td>\n",
       "      <td>4124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>2655.0</td>\n",
       "      <td>4615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>1758.0</td>\n",
       "      <td>5957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>2244.0</td>\n",
       "      <td>2745.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean      std\n",
       "STABBR                 \n",
       "AK      2493.0   4052.0\n",
       "AL      2790.0   4658.0\n",
       "AR      1644.0   3143.0\n",
       "AS      1276.0      NaN\n",
       "AZ      4130.0  14894.0\n",
       "...        ...      ...\n",
       "VT      1513.0   2194.0\n",
       "WA      2271.0   4124.0\n",
       "WI      2655.0   4615.0\n",
       "WV      1758.0   5957.0\n",
       "WY      2244.0   2745.0\n",
       "\n",
       "[59 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data_1/college.csv')\n",
    "(college\n",
    "    .groupby('STABBR')\n",
    "    ['UGDS']\n",
    "    .agg(['mean', 'std'])\n",
    "    .round(0)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output isn't quite what we desire. We are not looking for the mean and standard\n",
    "deviations of the entire group but the maximum number of standard deviations away\n",
    "from the mean for any one institution. To calculate this, we need to subtract the mean\n",
    "undergraduate population by state from each institution's undergraduate population\n",
    "and then divide by the standard deviation. This standardizes the undergraduate\n",
    "population for each group. We can then take the maximum of the absolute value of\n",
    "these scores to find the one that is farthest away from the mean. pandas does not\n",
    "provide a function capable of doing this. Instead, we will need to create a custom\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_deviation(s):\n",
    "    std_score = (s - s.mean()) / s.std()\n",
    "    return std_score.abs().max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the function, pass it directly to the .agg method to complete the\n",
    "aggregation. You will notice that the function name is placed inside the .agg method without\n",
    "directly being called. Nowhere is the parameter s explicitly passed to max_deviation.\n",
    "Instead, pandas implicitly passes the UGDS column as a Series to max_deviation.\n",
    "The max_deviation function is called once for each group. As s is a Series, all normal\n",
    "Series methods are available. It subtracts the mean of that particular grouping from each\n",
    "of the values in the group before dividing by the standard deviation in a process called\n",
    "standardization.\n",
    "\n",
    "pandas defaults to using the sample standard deviation, which is undefined for any groups\n",
    "with just a single value. For instance, the state abbreviation AS (American Samoa) has a\n",
    "missing value returned as it has only a single institution in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AK    2.6\n",
       "AL    5.8\n",
       "AR    6.3\n",
       "AS    NaN\n",
       "AZ    9.9\n",
       "     ... \n",
       "VT    3.8\n",
       "WA    6.6\n",
       "WI    5.8\n",
       "WV    7.2\n",
       "WY    2.8\n",
       "Name: UGDS, Length: 59, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(college\n",
    "    .groupby('STABBR')\n",
    "    ['UGDS']\n",
    "    .agg(max_deviation)\n",
    "    .round(1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use your custom aggregation function along with the prebuilt functions. The\n",
    "following does this and groups by state and religious affiliation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">UGDS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SATVRMID</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SATMTMID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max_deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max_deviation</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AK</th>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>3508.9</td>\n",
       "      <td>4539.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>123.3</td>\n",
       "      <td>132.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AL</th>\n",
       "      <th>0</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3248.8</td>\n",
       "      <td>5102.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>514.9</td>\n",
       "      <td>56.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>515.8</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.4</td>\n",
       "      <td>979.7</td>\n",
       "      <td>870.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>498.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>485.6</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>1793.7</td>\n",
       "      <td>3401.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>481.1</td>\n",
       "      <td>37.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>503.6</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WI</th>\n",
       "      <th>0</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2879.1</td>\n",
       "      <td>5031.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>558.8</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>591.2</td>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.4</td>\n",
       "      <td>1716.2</td>\n",
       "      <td>1934.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>500.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>526.6</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WV</th>\n",
       "      <th>0</th>\n",
       "      <td>6.9</td>\n",
       "      <td>1873.9</td>\n",
       "      <td>6271.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>466.7</td>\n",
       "      <td>27.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>480.0</td>\n",
       "      <td>27.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>716.4</td>\n",
       "      <td>503.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>485.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>484.8</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <th>0</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2244.4</td>\n",
       "      <td>2744.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         UGDS                      SATVRMID               \\\n",
       "                max_deviation    mean     std max_deviation   mean   std   \n",
       "STABBR RELAFFIL                                                            \n",
       "AK     0                 2.1   3508.9  4539.5          NaN     NaN   NaN   \n",
       "       1                 1.1    123.3   132.9          NaN   555.0   NaN   \n",
       "AL     0                 5.2   3248.8  5102.4          1.6   514.9  56.5   \n",
       "       1                 2.4    979.7   870.8          1.5   498.0  53.0   \n",
       "AR     0                 5.8   1793.7  3401.6          1.9   481.1  37.9   \n",
       "...                      ...      ...     ...          ...     ...   ...   \n",
       "WI     0                 5.3   2879.1  5031.5          1.3   558.8  47.5   \n",
       "       1                 3.4   1716.2  1934.6          2.1   500.1  66.0   \n",
       "WV     0                 6.9   1873.9  6271.7          1.6   466.7  27.9   \n",
       "       1                 1.3    716.4   503.6          1.9   485.7  14.6   \n",
       "WY     0                 2.8   2244.4  2744.7          NaN   535.0   NaN   \n",
       "\n",
       "                     SATMTMID               \n",
       "                max_deviation   mean   std  \n",
       "STABBR RELAFFIL                             \n",
       "AK     0                 NaN     NaN   NaN  \n",
       "       1                 NaN   503.0   NaN  \n",
       "AL     0                 1.7   515.8  56.7  \n",
       "       1                 1.4   485.6  61.4  \n",
       "AR     0                 2.0   503.6  39.0  \n",
       "...                      ...     ...   ...  \n",
       "WI     0                 1.3   591.2  85.7  \n",
       "       1                 1.8   526.6  42.5  \n",
       "WV     0                 1.8   480.0  27.7  \n",
       "       1                 1.7   484.8  17.7  \n",
       "WY     0                 NaN   540.0   NaN  \n",
       "\n",
       "[112 rows x 9 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(college\n",
    "    .groupby(['STABBR', 'RELAFFIL']) \n",
    "    [['UGDS', 'SATVRMID', 'SATMTMID']] \n",
    "    .agg([max_deviation, 'mean', 'std'])\n",
    "    .round(1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing aggregating functions with *args and **kwargs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing your own user-defined customized aggregation function, pandas implicitly\n",
    "passes it each of the aggregating columns one at a time as a Series. Occasionally, you\n",
    "will need to pass more arguments to your function than just the Series itself. To do so, you\n",
    "need to be aware of Python's ability to pass an arbitrary number of arguments to functions.\n",
    "\n",
    "The signature to .agg is __agg(func, *args, **kwargs)__. The func parameter is\n",
    "a reducing function, the string name of a reducing method, a list of reducing functions,\n",
    "or a dictionary mapping columns to functions or a list of functions. Additionally, as we have\n",
    "seen, you can use keyword arguments to create named aggregations.\n",
    "\n",
    "If you have a reducing function that takes additional arguments that you would like to use,\n",
    "you can leverage the *args and **kwargs parameters to pass arguments to the reduction\n",
    "function. You can use *args to pass an arbitrary number of positional arguments to your\n",
    "customized aggregation function. Similarly, **kwargs allows you to pass an arbitrary\n",
    "number of keyword arguments.\n",
    "\n",
    "In this recipe, we will build a customized function for the college dataset that finds the\n",
    "percentage of schools by state and religious affiliation that have an undergraduate population\n",
    "between two values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that returns the percentage of schools with an undergraduate\n",
    "population of between 1,000 and 3,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_between_1_3k(s):\n",
    "    return (s\n",
    "        .between(1_000, 3_000)\n",
    "        .mean()\n",
    "        * 100\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate this percentage grouping by state and religious affiliation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           14.3\n",
       "        1            0.0\n",
       "AL      0           23.6\n",
       "        1           33.3\n",
       "AR      0           27.9\n",
       "                    ... \n",
       "WI      0           13.8\n",
       "        1           36.0\n",
       "WV      0           24.6\n",
       "        1           37.5\n",
       "WY      0           54.5\n",
       "Name: UGDS, Length: 112, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(college\n",
    "    .groupby(['STABBR', 'RELAFFIL'])\n",
    "    ['UGDS'] \n",
    "    .agg(pct_between_1_3k)\n",
    "    .round(1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function works, but it does not give the user any flexibility to choose the lower\n",
    "and upper bound. Let's create a new function that allows the user to parameterize\n",
    "these bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_between(s, low, high):\n",
    "    return s.between(low, high).mean() * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass this new function to the .agg method along with the lower and upper bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           42.9\n",
       "        1            0.0\n",
       "AL      0           45.8\n",
       "        1           37.5\n",
       "AR      0           39.7\n",
       "                    ... \n",
       "WI      0           31.0\n",
       "        1           44.0\n",
       "WV      0           29.2\n",
       "        1           37.5\n",
       "WY      0           72.7\n",
       "Name: UGDS, Length: 112, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(college\n",
    "    .groupby(['STABBR', 'RELAFFIL'])\n",
    "    ['UGDS'] \n",
    "    .agg(pct_between, 1_000, 10_000)\n",
    "    .round(1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways we could achieve the same result in step 4. We could have explicitly\n",
    "used keyword parameters to produce the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           42.9\n",
       "        1            0.0\n",
       "AL      0           45.8\n",
       "        1           37.5\n",
       "AR      0           39.7\n",
       "                    ... \n",
       "WI      0           31.0\n",
       "        1           44.0\n",
       "WV      0           29.2\n",
       "        1           37.5\n",
       "WY      0           72.7\n",
       "Name: UGDS, Length: 112, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(college\n",
    "    .groupby(['STABBR', 'RELAFFIL'])\n",
    "    ['UGDS'] \n",
    "    .agg(pct_between, high=10_000, low=1_000)\n",
    "    .round(1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the groupby object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The immediate result from using the .groupby method on a DataFrame is a groupby object.\n",
    "Usually, we chain operations on this object to do aggregations or transformations without ever\n",
    "storing the intermediate values in variables.\n",
    "\n",
    "In this recipe, we examine the groupby object to examine individual groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by grouping the state and religious affiliation columns from the\n",
    "college dataset, saving the result to a variable and confirming its type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data_1/college.csv')\n",
    "grouped = college.groupby(['STABBR', 'RELAFFIL'])\n",
    "type(grouped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dir function to discover the attributes of a groupby object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CITY',\n",
      " 'CURROPER',\n",
      " 'DISTANCEONLY',\n",
      " 'GRAD_DEBT_MDN_SUPP',\n",
      " 'HBCU',\n",
      " 'INSTNM',\n",
      " 'MD_EARN_WNE_P10',\n",
      " 'MENONLY',\n",
      " 'PCTFLOAN',\n",
      " 'PCTPELL',\n",
      " 'PPTUG_EF',\n",
      " 'RELAFFIL',\n",
      " 'SATMTMID',\n",
      " 'SATVRMID',\n",
      " 'STABBR',\n",
      " 'UG25ABV',\n",
      " 'UGDS',\n",
      " 'UGDS_2MOR',\n",
      " 'UGDS_AIAN',\n",
      " 'UGDS_ASIAN',\n",
      " 'UGDS_BLACK',\n",
      " 'UGDS_HISP',\n",
      " 'UGDS_NHPI',\n",
      " 'UGDS_NRA',\n",
      " 'UGDS_UNKN',\n",
      " 'UGDS_WHITE',\n",
      " 'WOMENONLY',\n",
      " 'agg',\n",
      " 'aggregate',\n",
      " 'all',\n",
      " 'any',\n",
      " 'apply',\n",
      " 'bfill',\n",
      " 'boxplot',\n",
      " 'corr',\n",
      " 'corrwith',\n",
      " 'count',\n",
      " 'cov',\n",
      " 'cumcount',\n",
      " 'cummax',\n",
      " 'cummin',\n",
      " 'cumprod',\n",
      " 'cumsum',\n",
      " 'describe',\n",
      " 'diff',\n",
      " 'dtypes',\n",
      " 'ewm',\n",
      " 'expanding',\n",
      " 'ffill',\n",
      " 'fillna',\n",
      " 'filter',\n",
      " 'first',\n",
      " 'get_group',\n",
      " 'groups',\n",
      " 'head',\n",
      " 'hist',\n",
      " 'idxmax',\n",
      " 'idxmin',\n",
      " 'indices',\n",
      " 'last',\n",
      " 'max',\n",
      " 'mean',\n",
      " 'median',\n",
      " 'min',\n",
      " 'ndim',\n",
      " 'ngroup',\n",
      " 'ngroups',\n",
      " 'nth',\n",
      " 'nunique',\n",
      " 'ohlc',\n",
      " 'pct_change',\n",
      " 'pipe',\n",
      " 'plot',\n",
      " 'prod',\n",
      " 'quantile',\n",
      " 'rank',\n",
      " 'resample',\n",
      " 'rolling',\n",
      " 'sample',\n",
      " 'sem',\n",
      " 'shift',\n",
      " 'size',\n",
      " 'skew',\n",
      " 'std',\n",
      " 'sum',\n",
      " 'tail',\n",
      " 'take',\n",
      " 'transform',\n",
      " 'value_counts',\n",
      " 'var']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint([attr for attr in dir(grouped) if not attr.startswith('_')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the number of groups with the `.ngroups` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.ngroups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the uniquely identifying labels for each group, look in the .groups attribute,\n",
    "which contains a dictionary of each unique group mapped to all the corresponding\n",
    "index labels of that group. Because we grouped by two columns, each of the keys has\n",
    "a tuple, one value for the STABBR column and another for the RELAFFIL column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AK', 0), ('AK', 1), ('AL', 0), ('AL', 1), ('AR', 0), ('AR', 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = list(grouped.groups)\n",
    "groups[:6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a single group with the .get_group method by passing it a tuple of an\n",
    "exact group label. For example, to get all the religiously affiliated schools in the state\n",
    "of Florida, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>The Bapt...</td>\n",
       "      <td>Graceville</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.3531</td>\n",
       "      <td>30800</td>\n",
       "      <td>20052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Barry Un...</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4361</td>\n",
       "      <td>44100</td>\n",
       "      <td>28250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Gooding ...</td>\n",
       "      <td>Panama City</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PrivacyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Bethune-...</td>\n",
       "      <td>Daytona ...</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>29400</td>\n",
       "      <td>36250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Johnson ...</td>\n",
       "      <td>Kissimmee</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>26300</td>\n",
       "      <td>20199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>Strayer ...</td>\n",
       "      <td>Coral Sp...</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49200</td>\n",
       "      <td>36173.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>Strayer ...</td>\n",
       "      <td>Fort Lau...</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49200</td>\n",
       "      <td>36173.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>Strayer ...</td>\n",
       "      <td>Miramar</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49200</td>\n",
       "      <td>36173.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>Strayer ...</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49200</td>\n",
       "      <td>36173.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>Strayer ...</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49200</td>\n",
       "      <td>36173.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           INSTNM         CITY STABBR  HBCU  MENONLY  ...  PCTPELL  PCTFLOAN  \\\n",
       "712   The Bapt...   Graceville     FL   0.0      0.0  ...   0.5878    0.5602   \n",
       "713   Barry Un...        Miami     FL   0.0      0.0  ...   0.5045    0.6733   \n",
       "714   Gooding ...  Panama City     FL   0.0      0.0  ...      NaN       NaN   \n",
       "715   Bethune-...  Daytona ...     FL   1.0      0.0  ...   0.7758    0.8867   \n",
       "724   Johnson ...    Kissimmee     FL   0.0      0.0  ...   0.6689    0.7384   \n",
       "...           ...          ...    ...   ...      ...  ...      ...       ...   \n",
       "7486  Strayer ...  Coral Sp...     FL   NaN      NaN  ...      NaN       NaN   \n",
       "7487  Strayer ...  Fort Lau...     FL   NaN      NaN  ...      NaN       NaN   \n",
       "7488  Strayer ...      Miramar     FL   NaN      NaN  ...      NaN       NaN   \n",
       "7489  Strayer ...        Miami     FL   NaN      NaN  ...      NaN       NaN   \n",
       "7490  Strayer ...        Miami     FL   NaN      NaN  ...      NaN       NaN   \n",
       "\n",
       "      UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "712    0.3531        30800            20052         \n",
       "713    0.4361        44100            28250         \n",
       "714       NaN          NaN      PrivacyS...         \n",
       "715    0.0647        29400            36250         \n",
       "724    0.2185        26300            20199         \n",
       "...       ...          ...              ...         \n",
       "7486      NaN        49200          36173.5         \n",
       "7487      NaN        49200          36173.5         \n",
       "7488      NaN        49200          36173.5         \n",
       "7489      NaN        49200          36173.5         \n",
       "7490      NaN        49200          36173.5         \n",
       "\n",
       "[89 rows x 27 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.get_group(('FL', 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call the .head method on your groupby object to get the first rows of\n",
    "each group together in a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama ...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Universi...</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge ...</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>40100</td>\n",
       "      <td>23370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Birmingh...</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.4809</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>44200</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Prince I...</td>\n",
       "      <td>Elmhurst</td>\n",
       "      <td>IL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>PrivacyS...</td>\n",
       "      <td>20992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>Pacific ...</td>\n",
       "      <td>Mangilao</td>\n",
       "      <td>GU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>PrivacyS...</td>\n",
       "      <td>PrivacyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>Touro Un...</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PrivacyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>Marinell...</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21200</td>\n",
       "      <td>9796.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>Universi...</td>\n",
       "      <td>St. Croix</td>\n",
       "      <td>VI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31800</td>\n",
       "      <td>15150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7419</th>\n",
       "      <td>Computer...</td>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>NM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21300</td>\n",
       "      <td>14250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           INSTNM        CITY STABBR  HBCU  MENONLY  ...  PCTPELL  PCTFLOAN  \\\n",
       "0     Alabama ...      Normal     AL   1.0      0.0  ...   0.7356    0.8284   \n",
       "1     Universi...  Birmingham     AL   0.0      0.0  ...   0.3460    0.5214   \n",
       "2     Amridge ...  Montgomery     AL   0.0      0.0  ...   0.6801    0.7795   \n",
       "10    Birmingh...  Birmingham     AL   0.0      0.0  ...   0.1920    0.4809   \n",
       "43    Prince I...    Elmhurst     IL   0.0      0.0  ...   0.7857    0.9375   \n",
       "...           ...         ...    ...   ...      ...  ...      ...       ...   \n",
       "5289  Pacific ...    Mangilao     GU   0.0      0.0  ...   0.9730    0.0000   \n",
       "6439  Touro Un...   Henderson     NV   0.0      0.0  ...   0.0000    0.2000   \n",
       "7352  Marinell...   Henderson     NV   NaN      NaN  ...      NaN       NaN   \n",
       "7404  Universi...   St. Croix     VI   NaN      NaN  ...      NaN       NaN   \n",
       "7419  Computer...  Las Cruces     NM   NaN      NaN  ...      NaN       NaN   \n",
       "\n",
       "      UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "0      0.1049        30300            33888         \n",
       "1      0.2422        39700          21941.5         \n",
       "2      0.8540        40100            23370         \n",
       "10     0.0152        44200            27000         \n",
       "43     0.6569  PrivacyS...            20992         \n",
       "...       ...          ...              ...         \n",
       "5289   0.2533  PrivacyS...      PrivacyS...         \n",
       "6439   0.4000          NaN      PrivacyS...         \n",
       "7352      NaN        21200           9796.5         \n",
       "7404      NaN        31800            15150         \n",
       "7419      NaN        21300            14250         \n",
       "\n",
       "[215 rows x 27 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for states with a minority majority"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we examined using Boolean arrays to filter rows. In a similar fashion, when using\n",
    "the .groupby method, we can filter out groups. The .filter method of the groupby object\n",
    "accepts a function that must return either True or False to indicate whether a group is kept.\n",
    "\n",
    "This .filter method applied after a call to the .groupby method is completely different to\n",
    "the DataFrame .filter method covered in the Selecting columns with methods recipe from\n",
    "Chapter 2, Essential DataFrame Operations.\n",
    "\n",
    "One thing to be aware of is that when the .filter method is applied, the result does not use\n",
    "the grouping columns as the index, but keeps the original index! The DataFrame .filter\n",
    "method filters columns, not values.\n",
    "\n",
    "In this recipe, we use the college dataset to find all the states that have more non-white\n",
    "undergraduate students than white. This is a dataset from the US, where whites form the\n",
    "majority and therefore, we are looking for states with a minority majority."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the college dataset, group by state, and display the total number of groups.\n",
    "This should equal the number of unique states retrieved from the .nunique Series\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data/college.csv', index_col='INSTNM')\n",
    "grouped = college.groupby('STABBR')\n",
    "grouped.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college['STABBR'].nunique() # verifying the same number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouped variable has a `.filter` method, which accepts a custom function\n",
    "that determines whether a group is kept. The custom function accepts a DataFrame\n",
    "of the current group and is required to return a Boolean. Let's define a function\n",
    "that calculates the total percentage of minority students and returns True if this\n",
    "percentage is greater than a user-defined threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_minority(df, threshold):\n",
    "    minority_pct = 1 - df['UGDS_WHITE']\n",
    "    total_minority = (df['UGDS'] * minority_pct).sum()\n",
    "    total_ugds = df['UGDS'].sum()\n",
    "    total_minority_pct = total_minority / total_ugds\n",
    "    return total_minority_pct > threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .filter method passed with the check_minority function and a\n",
    "threshold of 50% to find all states that have a minority majority:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTNM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Everest College-Phoenix</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.7151</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>28600</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collins College</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7205</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.4764</td>\n",
       "      <td>25700</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empire Beauty School-Paradise Valley</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>17800</td>\n",
       "      <td>9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empire Beauty School-Tucson</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.4229</td>\n",
       "      <td>18200</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thunderbird School of Global Management</th>\n",
       "      <td>Glendale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>118900</td>\n",
       "      <td>PrivacyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WestMed College - Merced</th>\n",
       "      <td>Merced</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15623.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vantage College</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAE Institute of Technology  San Francisco</th>\n",
       "      <td>Emeryville</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bay Area Medical Academy - San Jose Satellite Location</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PrivacyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Excel Learning Center-San Antonio South</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3028 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CITY STABBR  HBCU  MENONLY  WOMENONLY  ...  PCTPELL  \\\n",
       "INSTNM                                                      ...            \n",
       "Everest C...      Phoenix     AZ   0.0      0.0        0.0  ...   0.8291   \n",
       "Collins C...      Phoenix     AZ   0.0      0.0        0.0  ...   0.7205   \n",
       "Empire Be...      Phoenix     AZ   0.0      0.0        0.0  ...   0.6349   \n",
       "Empire Be...       Tucson     AZ   0.0      0.0        0.0  ...   0.7962   \n",
       "Thunderbi...     Glendale     AZ   0.0      0.0        0.0  ...   0.0000   \n",
       "...                   ...    ...   ...      ...        ...  ...      ...   \n",
       "WestMed C...       Merced     CA   NaN      NaN        NaN  ...      NaN   \n",
       "Vantage C...      El Paso     TX   NaN      NaN        NaN  ...      NaN   \n",
       "SAE Insti...   Emeryville     CA   NaN      NaN        NaN  ...      NaN   \n",
       "Bay Area ...     San Jose     CA   NaN      NaN        NaN  ...      NaN   \n",
       "Excel Lea...  San Antonio     TX   NaN      NaN        NaN  ...      NaN   \n",
       "\n",
       "              PCTFLOAN  UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "INSTNM                                                                \n",
       "Everest C...    0.7151   0.6700        28600             9500         \n",
       "Collins C...    0.8228   0.4764        25700            47000         \n",
       "Empire Be...    0.5873   0.4651        17800             9588         \n",
       "Empire Be...    0.6615   0.4229        18200             9833         \n",
       "Thunderbi...    0.0000   0.0000       118900      PrivacyS...         \n",
       "...                ...      ...          ...              ...         \n",
       "WestMed C...       NaN      NaN          NaN          15623.5         \n",
       "Vantage C...       NaN      NaN          NaN             9500         \n",
       "SAE Insti...       NaN      NaN          NaN             9500         \n",
       "Bay Area ...       NaN      NaN          NaN      PrivacyS...         \n",
       "Excel Lea...       NaN      NaN          NaN            12125         \n",
       "\n",
       "[3028 rows x 26 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered = grouped.filter(check_minority, threshold=.5)\n",
    "college_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the output may not be indicative of what happened. The DataFrame\n",
    "starts with the state of Arizona (AZ) and not Alaska (AK), so we can visually confirm\n",
    "that something changed. Let's compare the shape of this filtered DataFrame with the\n",
    "original. Looking at the results, about 60% of the rows have been filtered, and only\n",
    "20 states remain that have a minority majority:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7535, 26)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3028, 26)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_filtered['STABBR'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming through a weight loss bet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transform` method in pandas is designed for performing group-wise operations on a DataFrame, allowing users to apply a function to each group independently and obtain results aligned with the original DataFrame's structure. It is a powerful tool for creating new columns or modifying existing ones based on group-specific calculations.\n",
    "\n",
    "In this recipe, we use simulated data from two individuals to track the percentage of weight loss over four months. The scenario in this recipe will track weight loss from two individuals throughout a four-month period and determine a winner. At the end of each month, a winner will be declared based on the individual who lost the highest percentage of body weight for that month. To track weight loss, we group our data by month and person, and then call the .transform method to find the percentage weight loss change for each week against the start of the month. \n",
    "\n",
    "We will use the .transform method in this recipe. This method returns a new object that\n",
    "preserves the index of the original DataFrame but allows you to do calculations on groups\n",
    "of the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the raw weight_loss dataset, and examine the first month of data from the two people, Amy and Bob. There are a total of four weigh-ins per month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name Month    Week  Weight\n",
       "0  Bob   Jan  Week 1     291\n",
       "1  Amy   Jan  Week 1     197\n",
       "2  Bob   Jan  Week 2     288\n",
       "3  Amy   Jan  Week 2     189\n",
       "4  Bob   Jan  Week 3     283\n",
       "5  Amy   Jan  Week 3     189\n",
       "6  Bob   Jan  Week 4     283\n",
       "7  Amy   Jan  Week 4     190"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_loss = pd.read_csv('data_1/weight_loss.csv')\n",
    "weight_loss.query('Month == \"Jan\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the winner for each month, we only need to compare weight loss from\n",
    "the first week to the last week of each month. But, if we wanted to have weekly\n",
    "updates, we can also calculate weight loss from the current week to the first week\n",
    "of each month. Let's create a function that is capable of providing weekly updates.\n",
    "It will take a Series and return a Series of the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_loss(s):\n",
    "    return ((s - s.iloc[0]) / s.iloc[0]) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out this function for Bob during the month of January:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "2   -1.030928\n",
       "4   -2.749141\n",
       "6   -2.749141\n",
       "Name: Weight, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .query('Name==\"Bob\" and Month==\"Jan\"')\n",
    "    ['Weight']\n",
    "    .pipe(percent_loss)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first week, Bob lost 1% of his body weight. He continued losing weight during\n",
    "the second week but made no progress during the last week. We can apply this\n",
    "function to every single combination of person and month to get the weight loss per\n",
    "week in relation to the first week of the month. To do this, we need to group our data\n",
    "by Name and Month, and then use the .transform method to apply this custom\n",
    "function. The function we pass to .transform needs to maintain the index of the\n",
    "group that is passed into it, so we can use percent_loss here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000000\n",
       "1     0.000000\n",
       "2    -1.030928\n",
       "3    -4.060914\n",
       "4    -2.749141\n",
       "        ...   \n",
       "27   -3.529412\n",
       "28   -3.065134\n",
       "29   -3.529412\n",
       "30   -4.214559\n",
       "31   -5.294118\n",
       "Name: Weight, Length: 32, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .groupby(['Name', 'Month'])\n",
    "    ['Weight'] \n",
    "    .transform(percent_loss)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .transform method takes a function that returns an object with the same\n",
    "index (and the same number of rows) as was passed into it. Because it has the\n",
    "same index, we can insert it as a column. The .transform method is useful for\n",
    "summarizing information from the groups and then adding it back to the original\n",
    "DataFrame. We will also filter down to two months of data for Bob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>percent_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>291</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>288</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>283</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>283</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 1</td>\n",
       "      <td>283</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 2</td>\n",
       "      <td>275</td>\n",
       "      <td>-2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 3</td>\n",
       "      <td>268</td>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>268</td>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  percent_loss\n",
       "0   Bob   Jan  Week 1     291          0.0 \n",
       "2   Bob   Jan  Week 2     288         -1.0 \n",
       "4   Bob   Jan  Week 3     283         -2.7 \n",
       "6   Bob   Jan  Week 4     283         -2.7 \n",
       "8   Bob   Feb  Week 1     283          0.0 \n",
       "10  Bob   Feb  Week 2     275         -2.8 \n",
       "12  Bob   Feb  Week 3     268         -5.3 \n",
       "14  Bob   Feb  Week 4     268         -5.3 "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .assign(percent_loss=(weight_loss\n",
    "        .groupby(['Name', 'Month'])\n",
    "        ['Weight'] \n",
    "        .transform(percent_loss)\n",
    "        .round(1)))\n",
    "    .query('Name==\"Bob\" and Month in [\"Jan\", \"Feb\"]')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the percentage of weight loss resets after the new month. With this new\n",
    "percent_loss column, we can manually determine a winner but let's see whether\n",
    "we can find a way to do this automatically. As the only week that matters is the last\n",
    "week, let's select week 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Weight</th>\n",
       "      <th>percent_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>283</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>190</td>\n",
       "      <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>268</td>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>173</td>\n",
       "      <td>-8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>261</td>\n",
       "      <td>-2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>170</td>\n",
       "      <td>-1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>250</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Week 4</td>\n",
       "      <td>161</td>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name Month    Week  Weight  percent_loss\n",
       "6   Bob   Jan  Week 4     283         -2.7 \n",
       "7   Amy   Jan  Week 4     190         -3.6 \n",
       "14  Bob   Feb  Week 4     268         -5.3 \n",
       "15  Amy   Feb  Week 4     173         -8.9 \n",
       "22  Bob   Mar  Week 4     261         -2.6 \n",
       "23  Amy   Mar  Week 4     170         -1.7 \n",
       "30  Bob   Apr  Week 4     250         -4.2 \n",
       "31  Amy   Apr  Week 4     161         -5.3 "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .assign(percent_loss=(weight_loss\n",
    "        .groupby(['Name', 'Month'])\n",
    "        ['Weight'] \n",
    "        .transform(percent_loss)\n",
    "        .round(1)))\n",
    "    .query('Week == \"Week 4\"')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This narrows down the weeks but still doesn't automatically find out the winner of\n",
    "each month. Let's reshape this data with the .pivot method so that Bob's and\n",
    "Amy's percent weight loss is side by side for each month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Amy</th>\n",
       "      <th>Bob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>-5.3</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>-8.9</td>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>-3.6</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>-2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name   Amy  Bob\n",
       "Month          \n",
       "Apr   -5.3 -4.2\n",
       "Feb   -8.9 -5.3\n",
       "Jan   -3.6 -2.7\n",
       "Mar   -1.7 -2.6"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .assign(percent_loss=(weight_loss\n",
    "        .groupby(['Name', 'Month'])\n",
    "        ['Weight'] \n",
    "        .transform(percent_loss)\n",
    "        .round(1)))\n",
    "    .query('Week == \"Week 4\"')\n",
    "    .pivot(index='Month', columns='Name',\n",
    "           values='percent_loss')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output makes it clearer who has won each month, but we can still go a couple\n",
    "of steps further. NumPy has a vectorized if then else function called where,\n",
    "which can map a Series or array of Booleans to other values. Let's create a column,\n",
    "winner, with the name of the winner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Amy</th>\n",
       "      <th>Bob</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>-5.3</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>Amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>-8.9</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>Amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>-3.6</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>Amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name   Amy  Bob winner\n",
       "Month                 \n",
       "Apr   -5.3 -4.2    Amy\n",
       "Feb   -8.9 -5.3    Amy\n",
       "Jan   -3.6 -2.7    Amy\n",
       "Mar   -1.7 -2.6    Bob"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .assign(percent_loss=(weight_loss\n",
    "        .groupby(['Name', 'Month'])\n",
    "        ['Weight'] \n",
    "        .transform(percent_loss)\n",
    "        .round(1)))\n",
    "    .query('Week == \"Week 4\"')\n",
    "    .pivot(index='Month', columns='Name',\n",
    "           values='percent_loss')\n",
    "    .assign(winner=lambda df_:\n",
    "            np.where(df_.Amy < df_.Bob, 'Amy', 'Bob'))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter, you can highlight the winning percentage for each month using the\n",
    ".style attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_2e29a346_2087_11ea_96f6_a45e60ecc33frow0_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_2e29a346_2087_11ea_96f6_a45e60ecc33frow1_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_2e29a346_2087_11ea_96f6_a45e60ecc33frow2_col0 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_2e29a346_2087_11ea_96f6_a45e60ecc33frow3_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33f\" ><thead>    <tr>        <th class=\"index_name level0\" >Name</th>        <th class=\"col_heading level0 col0\" >Amy</th>        <th class=\"col_heading level0 col1\" >Bob</th>        <th class=\"col_heading level0 col2\" >winner</th>    </tr>    <tr>        <th class=\"index_name level0\" >Month</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33flevel0_row0\" class=\"row_heading level0 row0\" >Apr</th>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow0_col0\" class=\"data row0 col0\" >-5.3</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow0_col1\" class=\"data row0 col1\" >-4.2</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow0_col2\" class=\"data row0 col2\" >Amy</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33flevel0_row1\" class=\"row_heading level0 row1\" >Feb</th>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow1_col0\" class=\"data row1 col0\" >-8.9</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow1_col1\" class=\"data row1 col1\" >-5.3</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow1_col2\" class=\"data row1 col2\" >Amy</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33flevel0_row2\" class=\"row_heading level0 row2\" >Jan</th>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow2_col0\" class=\"data row2 col0\" >-3.6</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow2_col1\" class=\"data row2 col1\" >-2.7</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow2_col2\" class=\"data row2 col2\" >Amy</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33flevel0_row3\" class=\"row_heading level0 row3\" >Mar</th>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow3_col0\" class=\"data row3 col0\" >-1.7</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow3_col1\" class=\"data row3 col1\" >-2.6</td>\n",
       "                        <td id=\"T_2e29a346_2087_11ea_96f6_a45e60ecc33frow3_col2\" class=\"data row3 col2\" >Bob</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11ace5e48>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .assign(percent_loss=(weight_loss\n",
    "        .groupby(['Name', 'Month'])\n",
    "        ['Weight'] \n",
    "        .transform(percent_loss)\n",
    "        .round(1)))\n",
    "    .query('Week == \"Week 4\"')\n",
    "    .pivot(index='Month', columns='Name',\n",
    "           values='percent_loss')\n",
    "    .assign(winner=lambda df_:\n",
    "            np.where(df_.Amy < df_.Bob, 'Amy', 'Bob'))\n",
    "    .style.highlight_min(axis=1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .value_counts method to return the final score as the number of months won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amy    3\n",
       "Bob    1\n",
       "Name: winner, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weight_loss\n",
    "    .assign(percent_loss=(weight_loss\n",
    "        .groupby(['Name', 'Month'])\n",
    "        ['Weight'] \n",
    "        .transform(percent_loss)\n",
    "        .round(1)))\n",
    "    .query('Week == \"Week 4\"')\n",
    "    .pivot(index='Month', columns='Name',\n",
    "           values='percent_loss')\n",
    "    .assign(winner=lambda df_:\n",
    "            np.where(df_.Amy < df_.Bob, 'Amy', 'Bob'))\n",
    "    .winner\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating weighted mean SAT scores per state with apply"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The groupby object has four methods that accept a function (or functions) to perform a\n",
    "calculation on each group. These four methods are .agg, .filter, .transform, and\n",
    ".apply. Each of the first three of these methods has a very specific output that the function\n",
    "must return. .agg must return a scalar value, .filter must return a Boolean, and\n",
    ".transform must return a Series or DataFrame with the same length as the passed group.\n",
    "The .apply method, however, may return a scalar value, a Series, or even a DataFrame\n",
    "of any shape, therefore making it very flexible. It is also called only once per group (on a\n",
    "DataFrame), while the .transform and .agg methods get called once for each aggregating\n",
    "column (on a Series). The .apply method's ability to return a single object when operating on\n",
    "multiple columns at the same time makes the calculation in this recipe possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this recipe, we calculate the weighted average of both the math and verbal SAT scores\n",
    "per state from the college dataset. We weight the scores by the population of undergraduate\n",
    "students per school.\n",
    "\n",
    "Read in the college dataset, and drop any rows that have missing values in the UGDS,\n",
    "SATMTMID, or SATVRMID columns. We do not want any missing values for those\n",
    "columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7535, 27)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('data_1/college.csv')\n",
    "subset = ['UGDS', 'SATMTMID', 'SATVRMID']\n",
    "college2 = college.dropna(subset=subset)\n",
    "college.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 27)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of institutions do not have data for our three required columns,\n",
    "but this is still more than enough data to continue. Next, create a user-defined\n",
    "function to calculate the weighted average of the SAT math scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_math_average(df):\n",
    "    weighted_math = df['UGDS'] * df['SATMTMID']\n",
    "    return int(weighted_math.sum() / df['UGDS'].sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by state and pass this function to the .apply method. Because each group\n",
    "has multiple columns and we want to reduce those to a single value, we need to use\n",
    ".apply. The weighted_math_average function will be called once for each group\n",
    "(not on the individual columns in the group):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR\n",
       "AK    503\n",
       "AL    536\n",
       "AR    529\n",
       "AZ    569\n",
       "CA    564\n",
       "     ... \n",
       "VT    566\n",
       "WA    555\n",
       "WI    593\n",
       "WV    500\n",
       "WY    540\n",
       "Length: 53, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college2.groupby('STABBR').apply(weighted_math_average)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully returned a scalar value for each group. Let's take a small detour and\n",
    "see what the outcome would have been by passing the same function to the .agg\n",
    "method (which calls the function for every column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UGDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:850\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    848\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:871\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 871\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:322\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    321\u001b[0m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[1;32m--> 322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m (\u001b[43mcollege2\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTABBR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_math_average\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1495\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m gba \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, [func], args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1495\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:178\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m    181\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:311\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1351\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_list_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;66;03m# Only set as_index=True on groupby objects, not Window or Resample\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;66;03m# that inherit from this class.\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1349\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1352\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:370\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[1;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(col, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj\u001b[38;5;241m.\u001b[39miloc[:, index])\n\u001b[0;32m    365\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    366\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    369\u001b[0m )\n\u001b[1;32m--> 370\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(colg, op_name)(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    371\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[0;32m    372\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:255\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m    254\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 255\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:360\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    359\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 360\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:297\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    299\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPinning the groupby key to each group in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.agg is deprecated, and cases that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;66;03m# result is a dict whose keys are the elements of result_index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:459\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_named\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m    455\u001b[0m ):\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# needed for pandas/tests/groupby/test_groupby.py::test_basic_aggregations\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m--> 459\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(group, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m     output \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mextract_result(output)\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'"
     ]
    }
   ],
   "source": [
    "(college2\n",
    "    .groupby('STABBR')\n",
    "    .agg(weighted_math_average)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted_math_average function gets applied to each non-aggregating\n",
    "column in the DataFrame. If you try and limit the columns to just SATMTMID, you\n",
    "will get an error as you won't have access to UGDS. So, the best way to complete\n",
    "operations that act on multiple columns is with .apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UGDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:292\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:325\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:850\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    848\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:871\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 871\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:322\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    321\u001b[0m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[1;32m--> 322\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m (\u001b[43mcollege2\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTABBR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSATMTMID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_math_average\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:297\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    299\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPinning the groupby key to each group in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.agg is deprecated, and cases that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;66;03m# result is a dict whose keys are the elements of result_index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:459\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_named\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m    455\u001b[0m ):\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# needed for pandas/tests/groupby/test_groupby.py::test_basic_aggregations\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m--> 459\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(group, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m     output \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mextract_result(output)\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m, in \u001b[0;36mweighted_math_average\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_math_average\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     weighted_math \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUGDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSATMTMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(weighted_math\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUGDS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\azatov\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'UGDS'"
     ]
    }
   ],
   "source": [
    "(college2\n",
    "    .groupby('STABBR')\n",
    "    ['SATMTMID'] \n",
    "    .agg(weighted_math_average)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature of .apply is that you can create multiple new columns by returning\n",
    "a Series. The index of this returned Series will be the new column names. Let's\n",
    "modify our function to calculate the weighted and arithmetic average for both SAT\n",
    "scores along with the count of the number of institutions from each group. We return\n",
    "these five values in a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_math_avg</th>\n",
       "      <th>w_verbal_avg</th>\n",
       "      <th>math_avg</th>\n",
       "      <th>verbal_avg</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>503</td>\n",
       "      <td>555</td>\n",
       "      <td>503</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>536</td>\n",
       "      <td>533</td>\n",
       "      <td>504</td>\n",
       "      <td>508</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>529</td>\n",
       "      <td>504</td>\n",
       "      <td>515</td>\n",
       "      <td>491</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>569</td>\n",
       "      <td>557</td>\n",
       "      <td>536</td>\n",
       "      <td>538</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>564</td>\n",
       "      <td>539</td>\n",
       "      <td>562</td>\n",
       "      <td>549</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>566</td>\n",
       "      <td>564</td>\n",
       "      <td>526</td>\n",
       "      <td>527</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA</th>\n",
       "      <td>555</td>\n",
       "      <td>541</td>\n",
       "      <td>551</td>\n",
       "      <td>548</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>593</td>\n",
       "      <td>556</td>\n",
       "      <td>545</td>\n",
       "      <td>516</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>500</td>\n",
       "      <td>487</td>\n",
       "      <td>481</td>\n",
       "      <td>473</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>540</td>\n",
       "      <td>535</td>\n",
       "      <td>540</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        w_math_avg  w_verbal_avg  math_avg  verbal_avg  count\n",
       "STABBR                                                       \n",
       "AK             503          555        503         555      1\n",
       "AL             536          533        504         508     21\n",
       "AR             529          504        515         491     16\n",
       "AZ             569          557        536         538      6\n",
       "CA             564          539        562         549     72\n",
       "...            ...          ...        ...         ...    ...\n",
       "VT             566          564        526         527      8\n",
       "WA             555          541        551         548     18\n",
       "WI             593          556        545         516     14\n",
       "WV             500          487        481         473     17\n",
       "WY             540          535        540         535      1\n",
       "\n",
       "[53 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_average(df):\n",
    "   weight_m = df['UGDS'] * df['SATMTMID']\n",
    "   weight_v = df['UGDS'] * df['SATVRMID']\n",
    "   wm_avg = weight_m.sum() / df['UGDS'].sum()\n",
    "   wv_avg = weight_v.sum() / df['UGDS'].sum()\n",
    "   data = {'w_math_avg': wm_avg,\n",
    "           'w_verbal_avg': wv_avg,\n",
    "           'math_avg': df['SATMTMID'].mean(),\n",
    "           'verbal_avg': df['SATVRMID'].mean(),\n",
    "           'count': len(df)\n",
    "   }\n",
    "   return pd.Series(data)\n",
    "\n",
    "(college2\n",
    "    .groupby('STABBR')\n",
    "    .apply(weighted_average)\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to finding just the arithmetic and weighted means, let's also find the geometric and\n",
    "harmonic means of both SAT columns and return the results as a DataFrame with rows as the\n",
    "name of the type of mean and columns as the SAT type. To ease the burden on us, we use the\n",
    "NumPy function average to compute the weighted average and the SciPy functions gmean and\n",
    "hmean for geometric and harmonic means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AK</th>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>503</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>503</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geometric</th>\n",
       "      <td>503</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmonic</th>\n",
       "      <td>503</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>504</td>\n",
       "      <td>508</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <th>Harmonic</th>\n",
       "      <td>480</td>\n",
       "      <td>472</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">WY</th>\n",
       "      <th>Arithmetic</th>\n",
       "      <td>540</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted</th>\n",
       "      <td>540</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geometric</th>\n",
       "      <td>540</td>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmonic</th>\n",
       "      <td>540</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SATMTMID  SATVRMID  count\n",
       "STABBR                                      \n",
       "AK     Arithmetic       503       555      1\n",
       "       Weighted         503       555      1\n",
       "       Geometric        503       555      1\n",
       "       Harmonic         503       555      1\n",
       "AL     Arithmetic       504       508     21\n",
       "...                     ...       ...    ...\n",
       "WV     Harmonic         480       472     17\n",
       "WY     Arithmetic       540       535      1\n",
       "       Weighted         540       535      1\n",
       "       Geometric        540       534      1\n",
       "       Harmonic         540       535      1\n",
       "\n",
       "[212 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import gmean, hmean\n",
    "def calculate_means(df):\n",
    "    df_means = pd.DataFrame(index=['Arithmetic', 'Weighted',\n",
    "                                   'Geometric', 'Harmonic'])\n",
    "    cols = ['SATMTMID', 'SATVRMID']\n",
    "    for col in cols:\n",
    "        arithmetic = df[col].mean()\n",
    "        weighted = np.average(df[col], weights=df['UGDS'])\n",
    "        geometric = gmean(df[col])\n",
    "        harmonic = hmean(df[col])\n",
    "        df_means[col] = [arithmetic, weighted,\n",
    "                         geometric, harmonic]\n",
    "    df_means['count'] = len(df)\n",
    "    return df_means.astype(int)\n",
    "\n",
    "(college2\n",
    "    .groupby('STABBR')\n",
    "    .apply(calculate_means)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by continuous variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When grouping in pandas, you typically use columns with discrete repeating values. If there\n",
    "are no repeated values, then grouping would be pointless as there would only be one row\n",
    "per group. Continuous numeric columns typically have few repeated values and are generally\n",
    "not used to form groups. However, if we can transform columns with continuous values into a\n",
    "discrete column by placing each value in a bin, rounding them, or using some other mapping,\n",
    "then grouping with them makes sense.\n",
    "In this recipe, we explore the flights dataset to discover the distribution of airlines for different\n",
    "travel distances. This allows us, for example, to find the airline that makes the most flights\n",
    "between 500 and 1,000 miles. To accomplish this, we use the pandas cut function to\n",
    "discretize the distance of each flight flown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>...</th>\n",
       "      <th>DIST</th>\n",
       "      <th>SCHED_ARR</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>...</td>\n",
       "      <td>590</td>\n",
       "      <td>1905</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>1452</td>\n",
       "      <td>1333</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>...</td>\n",
       "      <td>641</td>\n",
       "      <td>1453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>...</td>\n",
       "      <td>1192</td>\n",
       "      <td>1935</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>...</td>\n",
       "      <td>1363</td>\n",
       "      <td>2225</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58487</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>...</td>\n",
       "      <td>1464</td>\n",
       "      <td>1045</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58488</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>F9</td>\n",
       "      <td>LAS</td>\n",
       "      <td>...</td>\n",
       "      <td>414</td>\n",
       "      <td>2050</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58489</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>...</td>\n",
       "      <td>262</td>\n",
       "      <td>1956</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58490</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>...</td>\n",
       "      <td>907</td>\n",
       "      <td>855</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58491</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>...</td>\n",
       "      <td>522</td>\n",
       "      <td>1146</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58492 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MONTH  DAY  WEEKDAY AIRLINE ORG_AIR  ...  DIST  SCHED_ARR  ARR_DELAY  \\\n",
       "0          1    1        4      WN     LAX  ...   590       1905       65.0   \n",
       "1          1    1        4      UA     DEN  ...  1452       1333      -13.0   \n",
       "2          1    1        4      MQ     DFW  ...   641       1453       35.0   \n",
       "3          1    1        4      AA     DFW  ...  1192       1935       -7.0   \n",
       "4          1    1        4      WN     LAX  ...  1363       2225       39.0   \n",
       "...      ...  ...      ...     ...     ...  ...   ...        ...        ...   \n",
       "58487     12   31        4      AA     SFO  ...  1464       1045      -19.0   \n",
       "58488     12   31        4      F9     LAS  ...   414       2050        4.0   \n",
       "58489     12   31        4      OO     SFO  ...   262       1956       -5.0   \n",
       "58490     12   31        4      WN     MSP  ...   907        855       34.0   \n",
       "58491     12   31        4      OO     SFO  ...   522       1146       -1.0   \n",
       "\n",
       "       DIVERTED  CANCELLED  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "...         ...        ...  \n",
       "58487         0          0  \n",
       "58488         0          0  \n",
       "58489         0          0  \n",
       "58490         0          0  \n",
       "58491         0          0  \n",
       "\n",
       "[58492 rows x 14 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data_1/flights.csv')\n",
    "flights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to find the distribution of airlines over a range of distances, we need to\n",
    "place the values of the DIST column into discrete bins. Let's use the pandas cut\n",
    "function to split the data into five bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (500.0, ...\n",
       "1        (1000.0,...\n",
       "2        (500.0, ...\n",
       "3        (1000.0,...\n",
       "4        (1000.0,...\n",
       "            ...     \n",
       "58487    (1000.0,...\n",
       "58488    (200.0, ...\n",
       "58489    (200.0, ...\n",
       "58490    (500.0, ...\n",
       "58491    (500.0, ...\n",
       "Name: DIST, Length: 58492, dtype: category\n",
       "Categories (5, interval[float64, right]): [(-inf, 2... < (200.0, ... < (500.0, ... < (1000.0,... < (2000.0,...]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [-np.inf, 200, 500, 1000, 2000, np.inf]\n",
    "cuts = pd.cut(flights['DIST'], bins=bins)\n",
    "cuts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ordered categorical Series is created. To help get an idea of what happened, let's\n",
    "count the values of each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIST\n",
       "(500.0, 1000.0]     20659\n",
       "(200.0, 500.0]      15874\n",
       "(1000.0, 2000.0]    14186\n",
       "(2000.0, inf]        4054\n",
       "(-inf, 200.0]        3719\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuts.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cuts Series can now be used to form groups. pandas allows you to pass many\n",
    "types into the .groupby method. Pass the cuts Series to the .groupby method\n",
    "and then call the .value_counts method on the AIRLINE column to find the\n",
    "distribution for each distance group. Notice that SkyWest (OO) makes up 33% of\n",
    "flights of less than 200 miles but only 16% of those between 200 and 500 miles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azatov\\AppData\\Local\\Temp\\ipykernel_4056\\1298420373.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(cuts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DIST           AIRLINE\n",
       "(-inf, 200.0]  OO         0.326\n",
       "               EV         0.289\n",
       "               MQ         0.211\n",
       "               DL         0.086\n",
       "               AA         0.052\n",
       "                          ...  \n",
       "(2000.0, inf]  AS         0.012\n",
       "               F9         0.004\n",
       "               EV         0.000\n",
       "               MQ         0.000\n",
       "               OO         0.000\n",
       "Name: proportion, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flights\n",
    "    .groupby(cuts)\n",
    "    ['AIRLINE']\n",
    "    .value_counts(normalize=True) \n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>EV</th>\n",
       "      <th>...</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIST</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under an Hour</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 Hour</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-2 Hours</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4 Hours</th>\n",
       "      <td>0.264</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+ Hours</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE          AA     AS     B6     DL     EV  ...     OO     UA     US  \\\n",
       "DIST                                             ...                        \n",
       "Under an ...  0.052  0.000  0.000  0.086  0.289  ...  0.326  0.027  0.000   \n",
       "1 Hour        0.071  0.001  0.007  0.189  0.156  ...  0.159  0.062  0.016   \n",
       "1-2 Hours     0.144  0.023  0.003  0.206  0.101  ...  0.106  0.131  0.025   \n",
       "2-4 Hours     0.264  0.016  0.003  0.165  0.016  ...  0.046  0.199  0.040   \n",
       "4+ Hours      0.212  0.012  0.080  0.171  0.000  ...  0.000  0.289  0.065   \n",
       "\n",
       "AIRLINE          VX     WN  \n",
       "DIST                        \n",
       "Under an ...  0.000  0.009  \n",
       "1 Hour        0.028  0.194  \n",
       "1-2 Hours     0.004  0.138  \n",
       "2-4 Hours     0.012  0.160  \n",
       "4+ Hours      0.074  0.046  \n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=['Under an Hour', '1 Hour', '1-2 Hours',\n",
    "        '2-4 Hours', '4+ Hours']\n",
    "cuts2 = pd.cut(flights['DIST'], bins=bins, labels=labels)\n",
    "(flights\n",
    "   .groupby(cuts2, observed=False)\n",
    "   ['AIRLINE']\n",
    "   .value_counts(normalize=True) \n",
    "   .round(3) \n",
    "   .unstack() \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the longest streak of on-time flights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important metrics for airlines is their on-time flight performance. The\n",
    "Federal Aviation Administration considers a flight delayed when it arrives at least 15 minutes\n",
    "later than its scheduled arrival time. pandas includes methods to calculate the total and\n",
    "percentage of on-time flights per airline. While these basic summary statistics are an\n",
    "important metric, there are other non-trivial calculations that are interesting, such as finding\n",
    "the length of consecutive on-time flights for each airline at each of its origin airports.\n",
    "\n",
    "In this recipe, we find the longest consecutive streak of on-time flights for each airline at\n",
    "each origin airport. This requires each value in a column to be aware of the value immediately\n",
    "following it. We make clever use of the .diff and .cumsum methods to find streaks before\n",
    "applying this methodology to each of the groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started with the flights dataset, let's practice counting streaks of ones\n",
    "with a small sample Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, 1, 1, 0, 1, 1, 1, 0])\n",
    "s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final representation of the streaks of ones will be a Series of the same length\n",
    "as the original with an independent count beginning from one for each streak. To get\n",
    "started, let's use the .cumsum method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "5    4\n",
       "6    5\n",
       "7    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = s.cumsum()\n",
    "s1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now accumulated all the ones going down the Series. Let's multiply this\n",
    "Series by the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    3\n",
       "5    4\n",
       "6    5\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only non-zero values where we originally had ones. This result is fairly close\n",
    "to what we desire. We just need to restart each streak at one instead of where the\n",
    "cumulative sum left off. Let's chain the .diff method, which subtracts the previous\n",
    "value from the current:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "2    1.0\n",
       "3   -2.0\n",
       "4    3.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7   -5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mul(s1).diff()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative value represents the end of a streak. We need to propagate the negative\n",
    "values down the Series and use them to subtract away the excess accumulation from\n",
    "step 2. To do this, we will make all non-negative values missing with the .where\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3   -2.0\n",
       "4    NaN\n",
       "5    NaN\n",
       "6    NaN\n",
       "7   -5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s\n",
    "    .mul(s.cumsum())\n",
    "    .diff()\n",
    "    .where(lambda x: x < 0)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now propagate these values down with the .ffill method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3   -2.0\n",
       "4   -2.0\n",
       "5   -2.0\n",
       "6   -2.0\n",
       "7   -5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s\n",
    "    .mul(s.cumsum())\n",
    "    .diff()\n",
    "    .where(lambda x: x < 0)\n",
    "    .ffill()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add this Series back to the cumulative sum to clear out the excess accumulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "5    2.0\n",
       "6    3.0\n",
       "7    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s\n",
    "    .mul(s.cumsum())\n",
    "    .diff()\n",
    "    .where(lambda x: x < 0)\n",
    "    .ffill()\n",
    "    .add(s.cumsum(), fill_value=0)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a working consecutive streak finder, we can find the longest streak\n",
    "per airline and origin airport. Let's read in the flights dataset and create a column\n",
    "to represent on-time arrival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th>ON_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58487</th>\n",
       "      <td>AA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58488</th>\n",
       "      <td>F9</td>\n",
       "      <td>LAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58489</th>\n",
       "      <td>OO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58490</th>\n",
       "      <td>WN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58491</th>\n",
       "      <td>OO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58492 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AIRLINE ORG_AIR  ON_TIME\n",
       "0          WN     LAX        0\n",
       "1          UA     DEN        1\n",
       "2          MQ     DFW        0\n",
       "3          AA     DFW        1\n",
       "4          WN     LAX        0\n",
       "...       ...     ...      ...\n",
       "58487      AA     SFO        1\n",
       "58488      F9     LAS        1\n",
       "58489      OO     SFO        1\n",
       "58490      WN     MSP        0\n",
       "58491      OO     SFO        1\n",
       "\n",
       "[58492 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = pd.read_csv('data_1/flights.csv')\n",
    "(flights\n",
    "    .assign(ON_TIME=flights['ARR_DELAY'].lt(15).astype(int))\n",
    "    [['AIRLINE', 'ORG_AIR', 'ON_TIME']]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our logic from the first seven steps to define a function that returns the maximum\n",
    "streak of ones for a given Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_streak(s):\n",
    "    s1 = s.cumsum()\n",
    "    return (s\n",
    "       .mul(s1)\n",
    "       .diff()\n",
    "       .where(lambda x: x < 0) \n",
    "       .ffill()\n",
    "       .add(s1, fill_value=0)\n",
    "       .max()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum streak of on-time arrivals per airline and origin airport along with\n",
    "the total number of flights and the percentage of on-time arrivals. First, sort the day\n",
    "of the year and the scheduled departure time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "      <th>max_streak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>ORG_AIR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AA</th>\n",
       "      <th>ATL</th>\n",
       "      <td>0.82</td>\n",
       "      <td>233</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEN</th>\n",
       "      <td>0.74</td>\n",
       "      <td>219</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFW</th>\n",
       "      <td>0.78</td>\n",
       "      <td>4006</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAH</th>\n",
       "      <td>0.80</td>\n",
       "      <td>196</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAS</th>\n",
       "      <td>0.79</td>\n",
       "      <td>374</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WN</th>\n",
       "      <th>LAS</th>\n",
       "      <td>0.77</td>\n",
       "      <td>2031</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAX</th>\n",
       "      <td>0.70</td>\n",
       "      <td>1135</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSP</th>\n",
       "      <td>0.84</td>\n",
       "      <td>237</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHX</th>\n",
       "      <td>0.77</td>\n",
       "      <td>1724</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFO</th>\n",
       "      <td>0.76</td>\n",
       "      <td>445</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean  size  max_streak\n",
       "AIRLINE ORG_AIR                        \n",
       "AA      ATL      0.82   233        15.0\n",
       "        DEN      0.74   219        17.0\n",
       "        DFW      0.78  4006        64.0\n",
       "        IAH      0.80   196        24.0\n",
       "        LAS      0.79   374        29.0\n",
       "...               ...   ...         ...\n",
       "WN      LAS      0.77  2031        39.0\n",
       "        LAX      0.70  1135        23.0\n",
       "        MSP      0.84   237        32.0\n",
       "        PHX      0.77  1724        33.0\n",
       "        SFO      0.76   445        17.0\n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(flights\n",
    "    .assign(ON_TIME=flights['ARR_DELAY'].lt(15).astype(int))\n",
    "    .sort_values(['MONTH', 'DAY', 'SCHED_DEP']) \n",
    "    .groupby(['AIRLINE', 'ORG_AIR'])\n",
    "    ['ON_TIME'] \n",
    "    .agg(['mean', 'size', max_streak])\n",
    "    .round(2)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework Assignment 1: Analyzing Sales Data**\n",
    "\n",
    "You are given a dataset containing sales data for an e-commerce website. The dataset (`task\\sales_data.csv`) has the following columns:\n",
    "\n",
    "- `Date`: Date of the sale.\n",
    "- `Product`: Name of the product sold.\n",
    "- `Category`: Category to which the product belongs.\n",
    "- `Quantity`: Number of units sold.\n",
    "- `Price`: Price per unit.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Group the data by the `Category` column and calculate the following aggregate statistics for each category:\n",
    "   - Total quantity sold.\n",
    "   - Average price per unit.\n",
    "   - Maximum quantity sold in a single transaction.\n",
    "2. Identify the top-selling product in each category based on the total quantity sold.\n",
    "3. Find the date on which the highest total sales (quantity * price) occurred."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework Assignment 2: Examining Customer Orders**\n",
    "\n",
    "You have a dataset (`task\\customer_orders.csv`) containing information about customer orders. The dataset has the following columns:\n",
    "\n",
    "- `OrderID`: Unique identifier for each order.\n",
    "- `CustomerID`: Unique identifier for each customer.\n",
    "- `Product`: Name of the product ordered.\n",
    "- `Quantity`: Number of units ordered.\n",
    "- `Price`: Price per unit.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Group the data by `CustomerID` and filter out customers who have made less than 20 orders.\n",
    "2. Identify customers who have ordered products with an average price per unit greater than $120.\n",
    "3. Find the total quantity and total price for each product ordered, and filter out products that have a total quantity less than 5 units."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework Assignment 3: Population Salary Analysis**\n",
    "\n",
    "1. \"task\\population.db\" sqlite database has `population` table.\n",
    "2. \"task\\population salary analysis.xlsx\" file defines Salary Band categories. <br />\n",
    "    Read the data from population table and calculate following measures:\n",
    "    - Percentage of population for each salary category;\n",
    "    - Average salary in each salary category;\n",
    "    - Median salary in each salary category;\n",
    "    - Number of population in each salary category;\n",
    "3. Calculate the same measures in each State\n",
    "\n",
    "Note: Use SQL only to select data from database. All the other calculations should be done in python."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
